{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad5cb7",
   "metadata": {},
   "source": [
    "# `banyan` Example 1: Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57516f4c",
   "metadata": {},
   "source": [
    "This notebook will illustrate the very basic usage of the Bayesian neural network (BNN) implementation in `banyan`. More details are given in the README and in the other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346af639",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88603f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from banyan import BNN, BLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185f33f",
   "metadata": {},
   "source": [
    "There are two main objects in `banyan`:\n",
    "- `BNN`: the Bayesian neural network model\n",
    "- `BLoss`: the logistic kernel loss function\n",
    "\n",
    "To set up a BNN with 4 input features and 1 output feature, 2 hidden layers of 8 units each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd87545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 4\n",
    "out_features = 1\n",
    "N_hidden = 2\n",
    "N_units = 8\n",
    "model = BNN(in_features, out_features, N_hidden, N_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d3d87",
   "metadata": {},
   "source": [
    "Meanwhile, setting up the loss function is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = BLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096fa50d",
   "metadata": {},
   "source": [
    "For the most part, these work just like any other `pytorch` models and loss functions respectively, and so can be ported directly into training scripts with minimal change required. \n",
    "\n",
    "One caveat to this is that forward passes on the model require an additional argument: `N_samples`, the number of outputs for each input (i.e. the number of samples to take over the network parameters).\n",
    "\n",
    "For example, if we consider a randomly sample a dataset (with labels) with 100 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1c1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((100, 4))\n",
    "y = torch.randn((100, 1))\n",
    "preds = model(x, N_samples=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0df633",
   "metadata": {},
   "source": [
    "`preds` is then shaped (100, 250, 1), i.e. (batch size, `N_samples`, `out_features`).\n",
    "\n",
    "This can then be fed directly to the loss function, alongside the data labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56adfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7675, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossfn(preds, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ce7aa",
   "metadata": {},
   "source": [
    "Another notebook gives a full training example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
